{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6897944,
          "sourceType": "datasetVersion",
          "datasetId": 3962399
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk6749261-create/Named-Entity-Recognition/blob/main/Another_copy_of_notebook3c4de1b180.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "purusinghvi_email_spam_classification_dataset_path = kagglehub.dataset_download('purusinghvi/email-spam-classification-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "76BpqOHn9PF3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T02:08:40.164836Z",
          "iopub.execute_input": "2025-09-07T02:08:40.16517Z",
          "iopub.status.idle": "2025-09-07T02:08:42.901086Z",
          "shell.execute_reply.started": "2025-09-07T02:08:40.165136Z",
          "shell.execute_reply": "2025-09-07T02:08:42.899824Z"
        },
        "id": "ym3e2xsy9PF5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T02:12:12.291973Z",
          "iopub.execute_input": "2025-09-07T02:12:12.292341Z",
          "iopub.status.idle": "2025-09-07T02:12:12.297301Z",
          "shell.execute_reply.started": "2025-09-07T02:12:12.292315Z",
          "shell.execute_reply": "2025-09-07T02:12:12.296409Z"
        },
        "id": "WCccMjxn9PF7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/kaggle/input/email-spam-classification-dataset/combined_data.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T02:12:57.323699Z",
          "iopub.execute_input": "2025-09-07T02:12:57.324019Z",
          "iopub.status.idle": "2025-09-07T02:13:01.13196Z",
          "shell.execute_reply.started": "2025-09-07T02:12:57.323984Z",
          "shell.execute_reply": "2025-09-07T02:13:01.130938Z"
        },
        "id": "CdTPXFe79PF8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-07T02:13:33.193885Z",
          "iopub.execute_input": "2025-09-07T02:13:33.194733Z",
          "iopub.status.idle": "2025-09-07T02:13:33.228701Z",
          "shell.execute_reply.started": "2025-09-07T02:13:33.194693Z",
          "shell.execute_reply": "2025-09-07T02:13:33.227457Z"
        },
        "id": "D03zCh8I9PF8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "bMZShU4B9c6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "dXo6aJmU9c4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "aZK6BMg29c3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"]=df[\"text\"].str.lower()"
      ],
      "metadata": {
        "id": "PrHB0Lod9cKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "df[\"text\"]=df[\"text\"].str.translate(str.maketrans(\" \",\" \",string.punctuation))"
      ],
      "metadata": {
        "id": "e18rHJhC9b4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Jeio3xZE9bp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "df[\"text\"]=df[\"text\"].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "id": "giE7TeQh9bn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "PjodfUAN9bCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words=stopwords.words(\"english\")\n",
        "stop_words.remove(\"not\")"
      ],
      "metadata": {
        "id": "3_TSkNsL9azv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  return[word for word in text if word not in stop_words]\n",
        "df[\"text\"] =df[\"text\"].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "cULV0ssz9ab4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "qZNyOsNB9aUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "Lemmatizer=WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "GzV3B1XfY-Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_words(text):\n",
        "  return[Lemmatizer.lemmatize(word) for word in text]\n",
        "df[\"text\"]=df[\"text\"].apply(lemmatize_words)"
      ],
      "metadata": {
        "id": "fOXwTufjY-F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ET4MIMo8Y-BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "WphiJ-5LY976"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['text'])\n"
      ],
      "metadata": {
        "id": "Kt4qyhYwY95J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "id": "WchhAKuHY93B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=tokenizer.texts_to_sequences(df['text'])\n",
        "print(sequences[0:5])"
      ],
      "metadata": {
        "id": "YAG_CUxhY90K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded=pad_sequences(sequences,maxlen=50,padding='post',truncating='post')\n",
        "print(padded[0:5])"
      ],
      "metadata": {
        "id": "Ijb6Nxc6qzEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(padded,df['label'],test_size=0.2)"
      ],
      "metadata": {
        "id": "6zl3dowyqzBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=64, input_length=200),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sbwb9B_hqy-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "i7QQ9REPqy0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred=model.predict(x_test)\n",
        "y_pred_classes=(y_pred>0.5).astype(\"int32\")\n",
        "print(classification_report(y_pred_classes,y_test))"
      ],
      "metadata": {
        "id": "6CQtXYTKqyiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cm=confusion_matrix(y_test,y_pred_classes)\n",
        "print (cm)"
      ],
      "metadata": {
        "id": "-slABNMtqydA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "counts = pd.Series(y_pred_classes.flatten()).value_counts()\n",
        "percentages = counts / len(y_pred_classes) * 100\n",
        "\n",
        "print(\"num-of-words\")\n",
        "print(counts)\n",
        "\n",
        "print(\"persentage\")\n",
        "print(percentages)\n"
      ],
      "metadata": {
        "id": "01FMXmcByp5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wFnrdLG9yps4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLyS2tp7ypWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}