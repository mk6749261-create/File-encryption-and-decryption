{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8165591,
          "sourceType": "datasetVersion",
          "datasetId": 4831777
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk6749261-create/Named-Entity-Recognition/blob/main/Another_copy_of_notebook6e0d3a5a96.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "clmentbisaillon_fake_and_real_news_dataset_path = kagglehub.dataset_download('clmentbisaillon/fake-and-real-news-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "pGHot4WHpBYs"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-26T20:45:08.174733Z",
          "iopub.execute_input": "2025-08-26T20:45:08.175051Z",
          "iopub.status.idle": "2025-08-26T20:45:11.257935Z",
          "shell.execute_reply.started": "2025-08-26T20:45:08.175025Z",
          "shell.execute_reply": "2025-08-26T20:45:11.256132Z"
        },
        "id": "yXqfpccipBYu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-26T20:46:14.363584Z",
          "iopub.execute_input": "2025-08-26T20:46:14.363904Z",
          "iopub.status.idle": "2025-08-26T20:46:14.369993Z",
          "shell.execute_reply.started": "2025-08-26T20:46:14.36388Z",
          "shell.execute_reply": "2025-08-26T20:46:14.368912Z"
        },
        "id": "9hkxsVSLpBYv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\")\n",
        "df2=pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fCzmFANUpBYv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-26T20:48:08.469841Z",
          "iopub.execute_input": "2025-08-26T20:48:08.470176Z",
          "iopub.status.idle": "2025-08-26T20:48:08.501557Z",
          "shell.execute_reply.started": "2025-08-26T20:48:08.470149Z",
          "shell.execute_reply": "2025-08-26T20:48:08.49987Z"
        },
        "id": "1cKgsrIYpBYw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"subject\"].value_counts()"
      ],
      "metadata": {
        "id": "oCsFRMdnpp26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "LBFgfQbwpzs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-26T20:51:13.945367Z",
          "iopub.execute_input": "2025-08-26T20:51:13.946793Z",
          "iopub.status.idle": "2025-08-26T20:51:13.962584Z",
          "shell.execute_reply.started": "2025-08-26T20:51:13.946748Z",
          "shell.execute_reply": "2025-08-26T20:51:13.961397Z"
        },
        "id": "uakhIUZ0pBYw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"subject\"].value_counts()"
      ],
      "metadata": {
        "id": "j_0S8SclsLsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"label\"]=1\n",
        "df2[\"label\"]=0"
      ],
      "metadata": {
        "id": "iwq0aYkusLos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df1, df2])\n",
        "df"
      ],
      "metadata": {
        "id": "FmWA4b0NsLjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "GB-NTMswsLgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "15NsPyG4sLdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "JGjVeY1usLau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated()"
      ],
      "metadata": {
        "id": "Ii9N64iqsLX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicated_rows=df[df.duplicated()]\n",
        "(duplicated_rows)"
      ],
      "metadata": {
        "id": "bwE-hNinsLVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "A5nIloa6sLSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "0DjuEraJsLPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "s_RMClV5sLMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop([\"subject\",\"date\"],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "G1aX-8AlsLJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Ur65hE9JsLHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"content\"]=df[\"title\"]+\" \"+df[\"text\"]"
      ],
      "metadata": {
        "id": "ioU5x3ensLEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "2XDXJefzsLCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content']=df['content'].str.lower()"
      ],
      "metadata": {
        "id": "FRz22fmBsLAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "df['content']=df['content'].str.translate(str.maketrans(\" \",\" \",string.punctuation))"
      ],
      "metadata": {
        "id": "lit4duvWm8YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'].head()"
      ],
      "metadata": {
        "id": "M-WE_HgXm8mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "df['content']=df['content'].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "id": "6f64mlg0m8-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'].head()"
      ],
      "metadata": {
        "id": "srfEGqto10hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "1KA2R_Brm9Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=stopwords.words('english')\n",
        "stop_words.remove('not')"
      ],
      "metadata": {
        "id": "C9LvJPR3m9Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  return[word for word in text if word not in stop_words]\n",
        "df['content']=df['content'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "BulOSSGUm9jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'].head()"
      ],
      "metadata": {
        "id": "Xr5xdJyvm9vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "id": "YCTKgCI3m977"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer=WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "  return[lemmatizer.lemmatize(word) for word in text]\n",
        "df['content']=df['content'].apply(lemmatize_text)"
      ],
      "metadata": {
        "id": "ALPT7KLf_2aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'].head()"
      ],
      "metadata": {
        "id": "-s0GAn8DH01B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integer Encoding before embedding"
      ],
      "metadata": {
        "id": "CWW-Gp9tjPAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "C_CcnEm0H0bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# نحدد أقصى عدد كلمات في القاموس (vocab)\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['content'])\n",
        "\n",
        "# القاموس الناتج\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-7YNv3f-Hzzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=tokenizer.texts_to_sequences(df['content'])\n",
        "print(sequences[0:5])"
      ],
      "metadata": {
        "id": "1JawH0VlsVCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded=pad_sequences(sequences,maxlen=50,padding='post',truncating='post')\n",
        "print(padded[0:5])"
      ],
      "metadata": {
        "id": "zBHjTc0csVAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(padded.shape)\n",
        "print(padded[0])"
      ],
      "metadata": {
        "id": "hdvaM-jVsU8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(padded,df['label'],test_size=0.2)"
      ],
      "metadata": {
        "id": "SPIGph-vsU6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=64, input_length=200),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "oKLqn1PEsU3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "HhpmbhiRsUxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred=model.predict(x_test)\n",
        "y_pred_classes=(y_pred>0.5).astype(\"int32\")\n",
        "print(classification_report(y_pred_classes,y_test))\n"
      ],
      "metadata": {
        "id": "gLBZCifgsUuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cm=confusion_matrix(y_test,y_pred_classes)\n",
        "print (cm)"
      ],
      "metadata": {
        "id": "OpCQNdWAVmZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disply=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[False,True])\n",
        "disply.plot(cmap=\"Blues\", values_format=\"d\")\n"
      ],
      "metadata": {
        "id": "dPxK9XaEVmH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud\n"
      ],
      "metadata": {
        "id": "bz8SrmJwVmFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "gUloat5HVmCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "real_text = \" \".join(df[df['label'] == 1]['content'].apply(lambda x: \" \".join(x)))\n",
        "\n",
        "\n",
        "fake_text = \" \".join(df[df['label'] == 0]['content'].apply(lambda x: \" \".join(x)))\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "wc_real = WordCloud(width=800, height=400, background_color=\"white\").generate(real_text)\n",
        "plt.imshow(wc_real, interpolation=\"bilinear\")\n",
        "plt.title(\"Te Most Words Repeat in The Real News\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "wc_fake = WordCloud(width=800, height=400, background_color=\"white\", colormap=\"Reds\").generate(fake_text)\n",
        "plt.imshow(wc_fake, interpolation=\"bilinear\")\n",
        "plt.title(\"The Most words repeat in The fack News\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_O94Pp5lgmSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = [\"BREAKING: GOP Chairman Grassley Has Had Enoug\"]\n",
        "seq = tokenizer.texts_to_sequences(sample)\n",
        "pad = pad_sequences(seq, maxlen=200, padding='post')\n",
        "pred = model.predict(pad)\n",
        "print(\"Real\" if pred[0][0] >= 0.5 else \"Fake\")\n"
      ],
      "metadata": {
        "id": "9Wz8M5S9sUpI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}